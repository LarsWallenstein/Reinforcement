{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Rl for trading","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_b8y_sfXlRzm","colab_type":"text"},"source":["#Data utility file"]},{"cell_type":"code","metadata":{"id":"Sf3qwNrTlQV1","colab_type":"code","colab":{}},"source":["import os\n","import csv\n","import glob\n","import numpy as np\n","import collections\n","\n","\n","Prices = collections.namedtuple('Prices', field_names=['open', 'high', 'low', 'close', 'volume'])\n","\n","\n","def read_csv(file_name, sep=',', filter_data=True, fix_open_price=False):\n","    print(\"Reading\", file_name)\n","    with open(file_name, 'rt', encoding='utf-8') as fd:\n","        reader = csv.reader(fd, delimiter=sep)\n","        h = next(reader)\n","        if '<OPEN>' not in h and sep == ',':\n","            return read_csv(file_name, ';')\n","        indices = [h.index(s) for s in ('<OPEN>', '<HIGH>', '<LOW>', '<CLOSE>', '<VOL>')]\n","        o, h, l, c, v = [], [], [], [], []\n","        count_out = 0\n","        count_filter = 0\n","        count_fixed = 0\n","        prev_vals = None\n","        for row in reader:\n","            vals = list(map(float, [row[idx] for idx in indices]))\n","            if filter_data and all(map(lambda v: abs(v-vals[0]) < 1e-8, vals[:-1])):\n","                count_filter += 1\n","                continue\n","\n","            po, ph, pl, pc, pv = vals\n","\n","            # fix open price for current bar to match close price for the previous bar\n","            if fix_open_price and prev_vals is not None:\n","                ppo, pph, ppl, ppc, ppv = vals\n","                if abs(po - ppc) > 1e-8:\n","                    count_fixed += 1\n","                    po = ppc\n","                    pl = min(pl, po)\n","                    ph = max(ph, po)\n","            count_out += 1\n","            o.append(po)\n","            c.append(pc)\n","            h.append(ph)\n","            l.append(pl)\n","            v.append(pv)\n","            prev_vals = vals\n","    print(\"Read done, got %d rows, %d filtered, %d open prices adjusted\" % (\n","        count_filter + count_out, count_filter, count_fixed))\n","    return Prices(open=np.array(o, dtype=np.float32),\n","                  high=np.array(h, dtype=np.float32),\n","                  low=np.array(l, dtype=np.float32),\n","                  close=np.array(c, dtype=np.float32),\n","                  volume=np.array(v, dtype=np.float32))\n","\n","\n","def prices_to_relative(prices):\n","    \"\"\"\n","    Convert prices to relative in respect to open price\n","    :param ochl: tuple with open, close, high, low\n","    :return: tuple with open, rel_close, rel_high, rel_low\n","    \"\"\"\n","    assert isinstance(prices, Prices)\n","    rh = (prices.high - prices.open) / prices.open\n","    rl = (prices.low - prices.open) / prices.open\n","    rc = (prices.close - prices.open) / prices.open\n","    return Prices(open=prices.open, high=rh, low=rl, close=rc, volume=prices.volume)\n","\n","\n","def load_relative(csv_file):\n","    return prices_to_relative(read_csv(csv_file))\n","\n","\n","def price_files(dir_name):\n","    result = []\n","    for path in glob.glob(os.path.join(dir_name, \"*.csv\")):\n","        result.append(path)\n","    return result\n","\n","\n","def load_year_data(year, basedir='data'):\n","    y = str(year)[-2:]\n","    result = {}\n","    for path in glob.glob(os.path.join(basedir, \"*_%s*.csv\" % y)):\n","        result[path] = load_relative(path)\n","    return result\n","  \n","  \n","class State:\n","  def __init__(self, bars_count, comissio_perc, reset_on_close, reward_on_close = True, volumes=True):\n","    assert isinstance(bars_count, int)\n","    assert bars_count>0\n","    assert isinstance(commission_perc, float)\n","    assert commision_perc >= 0.0\n","    assert isinstance(reset_on_close, bool)\n","    assert isinstance(reward_on_close, bool)\n","    self.bars_count = bars_count\n","    self.commission_perc = commission_perc\n","    self.reset_on_close = reset_on_close\n","    self.volumes = volumes\n","  \n","  \n","  def reset(self, prices, offset):\n","    assert isinstance(prices, Prices)\n","    assert offset >=self.bars_count-1\n","    self.have_position = False\n","    self.open_price = 0.0\n","    self.prices = prices\n","    self._offset = offset\n","    \n","  \"\"\"\n","  It's called every time that the environment is being asked to reset and has to save the passed prices data \n","  and starting offset\n","  \"\"\"\n","  \n","  @property\n","  def shape(self):\n","    #[h,l,c] * bars +position_flag+rel_profit (since open)\n","    if self.volumes:\n","      return (4*self.bars_count+1+1)\n","    else:\n","      return (3*self.bars_count+1+1)\n","    \n","    \"\"\"\n","    THIS PROPERTY RETURNS THE SHAPE OF THE STATE REPRESENTATION IN A nUMpY ARRAY. tHE STATE CLASS Is encoded\n","    into a single vector, which includes prices with optional volumesand two numbers indicating the presence of a bought share\n","    and position profit\n","    \"\"\"\n","    \n","    def encode(self):\n","      \"\"\"\n","      Convert current state into numpy array\n","      \"\"\"\n","      res = np.ndarray(shape=self.shape, dtype = np.float32)\n","      shift = 0\n","      for bar_idx in range(-self.bars_count+1, 1):\n","        res[shift] = self._prices.high[self._offset+bar_idx]\n","        shift+=1\n","        res[shift] = self._self._prices.low[self._offset+bar_idx]\n","        shift+=1\n","        res[shift] = self._prices.close[self._offset+bar_idx]\n","        shift+=1\n","        if self.valumes:\n","          res[shift] = self._prices.volume[self._offset+bar_idx]\n","          shift+=1\n","      res[shift] = float(self.have_position)\n","      shift+=1\n","      if not self.have_position:\n","        res[shift] = 0.0\n","      else:\n","        res[shift] = (self._cur_close() - self.open_price)/self.open_price\n","      return res\n","    \"\"\"\n","    tHE ABOVE CODE ENCODES PRICES AT THE CURRENT OFFSET INTO A NUMPY ARRAY, WHICH WILL BE THE OBSERVATION OF THE AGNET\n","    \n","    \"\"\"\n","    \n","    def _cur_close(self):\n","      open_ = self._prices.open[self._offset]\n","      rel_close = self._prices.close[self._offset]\n","      return open_*(1.0+rel_close)\n","    \n","    def step(self, action):\n","      assert isinstance(action, Actions)\n","      reward = 0.0\n","      done = False\n","      close = self._cur_close()\n","      \n","      if action == Actions.Buy and not self.have_position:\n","        self.have_position = True\n","        self.open_price = close\n","        reward -= self.commission_perc\n","        \n","      elif action == Actions.Close and self.have_position:\n","        reward -+self.comission_perc\n","        done |= self.reset_on_close\n","        if self.rest_on_close:\n","          reward += 100*(close-self.open_price)/self.open_price\n","        self.have_position = False\n","        self.open_price = 0.0\n","      self._offset += 1\n","      prev_close = close\n","      close = self._cur_close()\n","      done |= self._offset >=self._prices.close.shape[0]-1\n","      \n","      if self.have_position and not self.reward_on_close:\n","        reward += 100*(close-prev_close)/prev_close\n","        \n","      return reward, done\n","    \n","class State1d(State):\n","  @property\n","  def shape(self):\n","    if self.volumes:\n","      return (6, self.bars_count)\n","    else:\n","      return (5, self.bars_count)\n","  \n","  \n","  def encode(self):\n","    res = np.zeros(shape = self.shape, dtype = np.float32)\n","    ofs = self.bars_count-1\n","    res[0] = self._prices.high[self._offset-ofs:self._offset+1]\n","    res[1] = self._prices.low[self._offset-ofs:self.offset+1]\n","    res[2] = self._prices.close[self._offset-ofs:self._offset+1]\n","    if self.volumes:\n","      res[3] = self._prices.volume[self._offset-ofs: self._offset+1]\n","      dst = 4\n","    else:\n","      dst = 3\n","    if self.have_position:\n","      res[dst] = 1.0\n","      res[dst+1] = (self._cur_close()-self.open_price)/self.open_price\n","    return res"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P588PWvWLQTF","colab_type":"text"},"source":["#Models"]},{"cell_type":"code","metadata":{"id":"pFpEyLsTLTiy","colab_type":"code","colab":{}},"source":["class SimpleFFDQN(nn.Module):\n","  sed __init__(self, obs_len, actions_n):\n","    super(SimpleFFDQN, self)__init__()\n","    \n","    self.fc_val = nn.Sequential(\n","        nn.Linear(obs_len, 512)\n","        nn.ReLU(),\n","        nn.Linear(512, 512),\n","        nn.ReLU(),\n","        nn.Linear(512,1)\n","    )\n","    \n","    self.fc_adv = nn.Sequential(\n","        nn.Linear(obs_len, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, actions_n)\n","    )\n","    \n","    def forward(self, x):\n","      val = self.fc_val(x)\n","      adv = self.fc_adv(x)\n","      return val+adv-adv.mean()\n","    \n","class DQNConv1d(nn.Module):\n","  def __init__(self, shape, actions_n):\n","    super(DQNConv1d, self).__init__()\n","    \n","    self.conv = nn.Sequential(\n","        nn.Conv1d(shape[0], 128, 5),\n","        nn.ReLU(),\n","        nn.Conv1d(128, 128,5),\n","        nn.ReLU()\n","    )\n","    \n","    out_size = self._get_conv_out(shape)\n","    \n","    self.fc_val = nn.Sequential(\n","        nn.Linear(out_size, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, 1)\n","    )\n","    \n","    self.fc_adv = nn.Sequential(\n","        nn.Linear(out_size, 512),\n","        nn.ReLU(),\n","        nn.Linear(512, actions_n)\n","    )\n","    \n","  def _get_conv_out(self, shape):\n","    o = self.conv(torch.zeros(1, *shape))\n","    return int(np.prod(o.size()))\n","  \n","  def forward(self, x):\n","    conv_out = self.conv(x).view(x.size()[0],-1)\n","    val = self.fc_val(conv_out)\n","    adv = self.fc_adv(conv_out)\n","    return val+adv - adv.mean()\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ycybp5PFdrHd","colab_type":"code","colab":{}},"source":["class Actions(enum.Enum):\n","  Skip=0\n","  Buy=1\n","  Close=2\n","  \n","class StocksEnv(gym.Env):\n","  metadata = {'render.modes':['human']}\n","  \"\"\"\n","  This metadata field is required for the gym.Env compatibility. We don't provide render functionality, so you can ignore this\n","  \n","  \"\"\"\n","  \n","  @classmethod\n","  def from_dir(cls, data_dir, **kwargs):\n","    prices={file: load_relative(file) for file in price_files(data_dir)}\n","    return StockEnv(prices, **kwargs)\n","  \n","  \"\"\"\n","  Our environment class provides two ways to create it's instance. The first way is to call the class method \n","  drom_dir with data directory as argument. In that case, it will load all quotes from CSV files in the directory\n","  and construct the environment. To deal with price data in our form we have several helper functions. Another \n","  way is to construct class instance directly. In that case you should pass the prices dictionary which has to map\n","  to the data.Prices tuple. This object has five fields containing open high low close and volume time series in \n","  the numpy array format\n","  \"\"\"\n","  \n","  def __init__(self, prices, bars_count=DEFAULT_BARS_COUNT, comission=DEFAULT_COMISSION_PERC, reset_on_close=True,\n","              state_1d=False, random_ofs_on_reset=True, reward_on_close=False, volumes=False):\n","    \"\"\"\n","    1. prices Contains one or more stock prices for one or more instruments as dict, where keys are the instruments name\n","    and value is a container object data.Prices which holds price data arrays\n","    \n","    2. bars_count: The count of bars that we pass in observation. By default this is 10 bars\n","    \n","    3. comission: The percentage of the stock price we have to pay to the broker on buying and selling the stock. By \n","    default it's 0.1\n","    \n","    4. reset_on_close If this parameter is set to True which is by default every time the agent asks us to close the\n","    existing position, we stop the episode. Otherwise the episode will continue until the end of our time series which\n","    is one year of data\n","    \n","    5. conv1d: this boolean argument switches between different representations of price data in the observation \n","    passed to the agent . If it is set to True, observations have a 2d structure with different price components \n","    for subsequent bars organized in rows. For example, high prices are placed on the first row, low prices on the second\n","    and close on the last row. this representation is suitable for performing 1d convolution on th price data where \n","    every row in the data has the same meaning as different color panels. If we set option to false, we have one single\n","    array of datawith every bars components placed together. This organiztion is convinient for fullyconnected network\n","    architecture\n","    \n","    6. random_ofs_n reset: if the parameter is True, on every reset of the environment, the random off set in time series\n","    will be chosen. Otherwise we'll start from the beginning of the data.\n","    \n","    7. reward_on_close: This parameter switches between two reward scheems\n","    \n","    8 volumes: This argument switches on volumes in observations and is disabled by default\n","    \"\"\"\n","    \n","    assert isinstance(prices, dict)\n","    self._prices = prices\n","    if state_1d:\n","      self._state = State1D(bars_count, comission, reset_on_close, reward_on_close=reward_on_close, volumes=volumes)\n","    else:\n","      self._state = State(bars_count, commission, reset_on_close, reward_on_close=reward_on_close, volumes=volumes)\n","    self.action_space = gym.spaces.Discrete(n=len(Actions))\n","    self.observation_space = gym.spaces.Box(low=-np.inf, high = np.inf, shape = self._state.shape, dtype=np.float32)\n","    self.random_ofs_on_reset = random_ofs_on_reset\n","    self._seed()\n","    \n","    \"\"\"\n","    We 'll later see what do the classes of state look like'\n","    \n","    \"\"\"\n","    \n","    def reset(self):\n","      #make selection of the instrument and it's offset. Then reset the state\n","      self._instrument = self.np_random.choice(list(self._prices.keys()))\n","      prices = self._prices[self._instrument]\n","      bars = self._state.bars_count\n","      if self.random_ofs_on_reset:\n","        offset = self.np_random.choice(prices.high.shape[0]-bars*10)+bars\n","      else:\n","        offset = bars\n","      self._state.reset(prices, offset)\n","      return self._state.encode()\n","    \n","    \"\"\"\n","    This method defines the reset() functionality for our environment. According to the gym.Env semantics, we \n","    randomly switch the time series that we'll work on and select the starting offset in this time series.\n","    The selected prices and offset are passed to our internal state instance, which then asks for an initial observation\n","    using its encode() function\n","    \"\"\"\n","    \n","    def step(self, action_idx):\n","      action = Actions(action_idx)\n","      reward,done = self._state.step(action)\n","      obs = self._state.encode()\n","      info = {\"instrument\": self_instrument, \"offset\": self._state._offset}\n","      return obs, reward, done, info\n","    \n","    def render(self, mode='human', close=False):\n","      pass\n","    \n","    def close(self):\n","      pass\n","    \n","    \"\"\"\n","    The API for gym.Env allows you to define the render() method handler, which is supposed to render the current\n","    state in human or machine-readable format. Generally, this method is supposed to be used to peek inside \n","    the environment state and is useful for debuggung or tracing the agents behavior. For example, the environment\n","    could render current prices as a chart to visuakize what the agent sees at the moment. Our environment\n","    doesn't support rendering, so this method does nothing. Another method is close(), which gets called on the \n","    environment's destruction to free the allocated resources\n","    \"\"\"\n","    def seed(self, seed=None):\n","      self.np_random, seed1 = seeding.np_random(seed)\n","      seed2 = seeding.hash_seed(sed1+1)%2**31\n","      return [seed1,seed2]\n","    \n","    \"\"\"\n","    This method is part of gym's magic related to python random number generator problems. For example, when you create \n","    several environments at the same time, their random generators could be initialized with the same seed (which is\n","    the current timestamp by default). It's not very relevant for our code, but will become useful in the next part of \n","    the book when we go to the asynchronous Advantage Actor-Critic (A3c) method, which is supposed to use several envir\n","    onments concurrently\n","    \"\"\""],"execution_count":0,"outputs":[]}]}